{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import warnings, glob, os, sys, shutil\n",
    "from tqdm.notebook import tqdm\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 過濾非生理數據與未使用特徵\n",
    "drop_cols = ['洗腎紀錄時間', '急診門診住院', '生日', '算年齡', \n",
    "             'DLC', 'PERMCATH', 'HBs', 'HBsAg', 'HBc', \n",
    "             \n",
    "             '體重2標準體重', '體重3應脫水', '體重結束', '分母體重', '體重機器顯示', \n",
    "             'BUN (洗腎後)', \n",
    "             'sbp', 'dbp', 'New Intra SBP', 'New Intra DBP',\n",
    "             'New 處置其他+症狀處置', 'New 處置其他結束', '處置其他結束', '處置其他', '症狀處置', 'NLP Judge', 'BP Judge']\n",
    "\n",
    "select_cols =  ['性別', '入院方式', 'HCV','HBV','有無糖尿病','FISTULA','GRAFT','Catheter','Intact PTH','age', '體重1開始','開始血壓SBP', '開始血壓DBP',\n",
    "            '開始脈搏', '體溫', '體重實際脫水','每公斤脫水量(ml/kg)','BUN','K', 'HGB','URR%','Na', 'Ca','P',\n",
    "            '透析液 Ca','ALBUMIN','ALT (SGPT)','Alk.phosphatase','Ferritin','IRON/TIBC','MCV', 'MCHC', 'MCH','Iron','Glucose AC','RBC', 'WBC',\n",
    "            'Platelet', 'Creatinine','AST (SGOT)','TIBC','Bilirubin-T', 'Cholesterol-T', 'CRP']\n",
    "select_cols = select_cols+ ['Max Diff mbp', 'Max Diff sbp','結束脈搏','Final Judge','Raw Index','ID','洗腎紀錄時間去時分']\n",
    "\n",
    "mask_cols = ['Max Diff mbp','Max Diff sbp', 'Final Judge','結束脈搏'] #'每公斤脫水量(ml/kg)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV process \n",
    "ths_days = 30 #change 30 => 90\n",
    "stack_nums = 12 #max = 12 / 16 lv.3=16, 8, 4\n",
    "input_nums = 8\n",
    "\n",
    "final_cv_save_path = './dataset/TimeSeries_TD{}_SN{}_IN{}_CV_[2025-04-25]'.format(ths_days, stack_nums, input_nums)\n",
    "os.makedirs(final_cv_save_path, exist_ok=True) #創建儲存路徑\n",
    "\n",
    "def data_ts_stack(group_data_type, group_ID_df, columns, ts_save_path):\n",
    "    for idx__, (group_name, group_data) in enumerate(tqdm(group_ID_df)):\n",
    "        # if group_data.ID.unique()[0] in ['07339W939', '07879B585']:\n",
    "        # if idx__ in [0,1,2,3,4,5]:\n",
    "        if True:\n",
    "            timeseries_df = pd.DataFrame([], columns=columns)\n",
    "            timeseries_df['Group Type'] = np.nan #標記Train、Valid、Test\n",
    "            group_data = group_data.sort_values(by=['洗腎紀錄時間去時分'], ascending=True)\n",
    "            group_data = group_data.reset_index(drop=True)\n",
    "            stop_tip = False\n",
    "            for idx in group_data.index:\n",
    "                slice_df = group_data.loc[idx:idx+(stack_nums-1)].copy()\n",
    "                \n",
    "                # print(slice_df.shape)\n",
    "                # if (group_data.shape[0]==stack_nums) and (slice_df.shape[0]==stack_nums) and (abs(slice_df['洗腎紀錄時間去時分'].iloc[0] - slice_df['洗腎紀錄時間去時分'].iloc[-1]).days<=ths_days): #判斷資料是否有{stack_nums}筆，以及區間時間是否小於等於{ths_days}\n",
    "                if (slice_df.shape[0]==stack_nums) and (abs(slice_df['洗腎紀錄時間去時分'].iloc[0] - slice_df['洗腎紀錄時間去時分'].iloc[-1]).days<=ths_days): #判斷資料是否有{stack_nums}筆，以及區間時間是否小於等於{ths_days}\n",
    "                    # print(group_data.shape[0])\n",
    "                    if stack_nums!=input_nums:\n",
    "                        slice_df = slice_df.iloc[(stack_nums-input_nums)::]\n",
    "                        slice_df = pd.concat([slice_df,slice_df.iloc[-1].to_frame().T.copy()])\n",
    "                    else: \n",
    "                        slice_df = pd.concat([slice_df,slice_df.iloc[-1].to_frame().T.copy()])\n",
    "                    slice_df.iloc[-2,slice_df.columns.get_indexer(mask_cols)] = -9999\n",
    "                    timeseries_df = pd.concat([timeseries_df,slice_df])\n",
    "                # elif group_data.shape[0]<=input_nums:\n",
    "                else:\n",
    "                    if stop_tip==False and group_data.shape[0]<stack_nums:\n",
    "                        stop_tip = True\n",
    "                        add_rows_num = input_nums - slice_df.shape[0]\n",
    "                        # print(slice_df['ID'].iloc[0], add_rows_num, stack_nums-input_nums, slice_df.shape)\n",
    "                        if add_rows_num!=0 and add_rows_num>0:\n",
    "                            stop_tip = True\n",
    "                            first_data = slice_df.iloc[0]\n",
    "                            stacked_rows = pd.concat([slice_df.iloc[0]] * add_rows_num, ignore_index=True, axis=1).T\n",
    "                            stacked_rows[:] = 9999\n",
    "                            stacked_rows['ID'] = first_data['ID']\n",
    "                            stacked_rows['洗腎紀錄時間去時分'] = first_data['洗腎紀錄時間去時分']\n",
    "                            # print(\"ADD:\", stacked_rows.shape)\n",
    "                            temp_df = pd.concat([stacked_rows, slice_df], axis=0)\n",
    "                            temp_df = pd.concat([temp_df,temp_df.iloc[-1].to_frame().T.copy()])\n",
    "                            temp_df.iloc[-2,temp_df.columns.get_indexer(mask_cols)] = -9999\n",
    "                            if len(temp_df)!=input_nums+1:\n",
    "                                print(0,\" Error Data:\",group_data.ID.unique(), temp_df.shape)\n",
    "                        elif slice_df.shape[0] ==input_nums:\n",
    "                            temp_df = pd.concat([slice_df,slice_df.iloc[-1].to_frame().T.copy()])\n",
    "                            temp_df.iloc[-2,temp_df.columns.get_indexer(mask_cols)] = -9999      \n",
    "                            if len(temp_df)!=input_nums+1:\n",
    "                                print(1,\" Error Data:\",group_data.ID.unique(), temp_df.shape)\n",
    "                        elif add_rows_num<0:\n",
    "                            # temp_df = slice_df.iloc[(stack_nums-input_nums)::]\n",
    "                            temp_df = slice_df.iloc[(add_rows_num*-1)::]\n",
    "                            temp_df = pd.concat([temp_df,temp_df.iloc[-1].to_frame().T.copy()])\n",
    "                            # print(add_rows_num, stack_nums-input_nums, slice_df.shape, temp_df.shape, temp_df['ID'].iloc[0],temp_df['Raw Index'])\n",
    "                            temp_df.iloc[-2,temp_df.columns.get_indexer(mask_cols)] = -9999\n",
    "                            if len(temp_df)!=input_nums+1:\n",
    "                                print(2,\" Error Data:\",group_data.ID.unique(), temp_df.shape)\n",
    "                        timeseries_df = pd.concat([timeseries_df,temp_df])\n",
    "                        # print(\"New ADD shape:\", timeseries_df.shape)\n",
    "                    # else:\n",
    "                    #     timeseries_df = group_data.head(input_nums)\n",
    "            if timeseries_df.shape[0]!=0:\n",
    "                timeseries_df.to_csv(os.path.join(ts_save_path,f'{group_data_type}-{str(group_name[0])}.csv'),encoding='utf-8-sig', index=False)\n",
    "            else:\n",
    "                print(\"Error Data:\",group_data.ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_ = {\n",
    "    # 'A':'./dataset/DATA_A_FinalFinished[2024-09-27-filter-age]fixed.csv',\n",
    "    # 'B':'./dataset/DATA_B_FinalFinished[2024-09-27-filter-age]fixed.csv',\n",
    "    'C':'./dataset/DATA_C_FinalFinished[2024-09-27-filter-age]fixed.csv',\n",
    "    'ET':'./dataset/DATA_test[2024-09-27_from_DATA_A].csv'\n",
    "    }\n",
    "# Data_ = {\n",
    "    # 'A':'./dataset/DATA_A_FinalFinished[2024-09-27-filter-age]fixed.csv',\n",
    "    # 'B':'./dataset/DATA_B_FinalFinished[2024-10-10-filger-age].csv',\n",
    "    # 'C':'./dataset/DATA_C_FinalFinished[2024-10-10-filter-age].csv',\n",
    "    # 'ET':'./dataset/DATA_test[2024-09-27_from_DATA_A].csv'\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0380f5657014ff2b1707b8887652c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/508 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Data: ['00E29U959']\n",
      "Error Data: ['01809M181']\n",
      "Error Data: ['01945R090']\n",
      "Error Data: ['01E59Y050']\n",
      "Error Data: ['02259W121']\n",
      "Error Data: ['03E84A151']\n",
      "Error Data: ['050117101']\n",
      "Error Data: ['05849G181']\n",
      "Error Data: ['06309J131']\n",
      "Error Data: ['064897545']\n",
      "Error Data: ['071795313']\n",
      "Error Data: ['07403C141']\n",
      "Error Data: ['07825B585']\n",
      "Error Data: ['09431M343']\n",
      "Error Data: ['097251373']\n",
      "Error Data: ['098969585']\n",
      "Error Data: ['09E0G1252']\n",
      "Error Data: ['134811545']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c7cb1e977645e0b28d814360c88e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1310499, 52)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da968db00c040ec95f5302446f71f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Data: ['03E36B555']\n",
      "Error Data: ['076717262']\n"
     ]
    }
   ],
   "source": [
    "for DATA_NAME in Data_:\n",
    "    filter_data_df = pd.read_csv(Data_[DATA_NAME])\n",
    "    filter_data_df = filter_data_df[select_cols]\n",
    "    filter_data_df['洗腎紀錄時間去時分'] = pd.to_datetime(filter_data_df['洗腎紀錄時間去時分']).dt.date\n",
    "    \n",
    "    # for cv_fold in ['fold_0','fold_1', 'fold_2', 'fold_3', 'fold_4']:\n",
    "    ts_save_path = './dataset/CV_temp_2/'\n",
    "    if os.path.exists(ts_save_path):\n",
    "        shutil.rmtree(ts_save_path)\n",
    "    os.makedirs(ts_save_path, exist_ok=True) #創建儲存路徑\n",
    "    group_ID_filter_data_df = filter_data_df.groupby(['ID'])\n",
    "    data_ts_stack('TrainVal', group_ID_filter_data_df, filter_data_df.columns, ts_save_path)\n",
    "    \n",
    "    patient_csv_glob = glob.glob(os.path.join(ts_save_path,'*'))\n",
    "    # trainval_df = pd.DataFrame([], columns=valid_df.columns)\n",
    "    trainval_df = pd.DataFrame([], columns=filter_data_df.columns)\n",
    "    for csv_path in tqdm(patient_csv_glob):\n",
    "        data_df = pd.read_csv(csv_path)\n",
    "        trainval_df = pd.concat([trainval_df,data_df])\n",
    "        del data_df\n",
    "    # save_name = \"TrainVal_{}_DATA-{}.csv\".format(cv_fold, DATA_NAME)\n",
    "    save_name = \"InternalTest_DATA-{}.csv\".format( DATA_NAME)\n",
    "    trainval_df.to_csv(os.path.join(final_cv_save_path, save_name), encoding='utf-8-sig', index=False)    \n",
    "    print(trainval_df.shape)\n",
    "    del trainval_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idh_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
