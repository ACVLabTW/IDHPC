{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, warnings\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from util import data_process\n",
    "from sklearn.metrics import f1_score, recall_score, roc_auc_score, confusion_matrix, accuracy_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 第一層全連接層\n",
    "        self.relu = nn.ReLU()                         # ReLU 激活函數\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) # 第二層全連接層\n",
    "        self.dp1 = nn.Dropout(0.25)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size) # 輸出層\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dp1(self.fc2(out))\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model = None, TrainData = None, ValidData = None, epochs = 20, opt = None, crit = None, save_path = None, fold_n = None):\n",
    "    best_recall = 0\n",
    "    best_loss = np.inf\n",
    "    patient = 1\n",
    "    # lambda1 = lambda epoch: opt.param_groups[0]['lr']*0.2 * epoch if epoch > 5 else 1\n",
    "    lambda2 = lambda epoch: 0.9 **epoch if epoch > 5 else 1\n",
    "    # scheduler = optim.lr_scheduler.LambdaLR(opt, lr_lambda=lambda1)\n",
    "    scheduler = optim.lr_scheduler.MultiplicativeLR(opt, lr_lambda=lambda2)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for i, (features, labels) in enumerate(TrainData):\n",
    "            # 向前傳播\n",
    "            outputs = model(features).squeeze(1)  # 輸出需要匹配 labels 的 shape\n",
    "            loss = crit(outputs, labels)\n",
    "\n",
    "            # 向後傳播和優化\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        scheduler.step()\n",
    "        if epoch%5==0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Learning Rate: {scheduler.get_last_lr()[0]}')\n",
    "        model.eval()\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        y_probs = []\n",
    "        y_loss = []\n",
    "        with torch.no_grad():\n",
    "            total = 0\n",
    "            for features, labels in ValidData:\n",
    "                outputs = model(features).squeeze(1)\n",
    "                loss = crit(outputs, labels)\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                predictions = probs > 0.5\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                y_true.extend(labels.tolist())\n",
    "                y_pred.extend(predictions.tolist())\n",
    "                y_probs.extend(probs.tolist())\n",
    "                y_loss.append(loss.item())\n",
    "            # print(y_true)\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            f1 = f1_score(y_true, y_pred, average='macro')\n",
    "            recall = recall_score(y_true, y_pred, average='macro')\n",
    "            auc = roc_auc_score(y_true, y_probs)\n",
    "            mean_loss = np.mean(y_loss)\n",
    "            # print(mean_loss)\n",
    "            # if recall > best_recall:\n",
    "            if mean_loss < best_loss:\n",
    "                patient=0\n",
    "                # best_recall = recall\n",
    "                best_loss = mean_loss\n",
    "                os.makedirs(save_path, exist_ok=True)\n",
    "                torch.save(model.state_dict(), os.path.join(save_path,f'best_model_cv{fold_n}.pth'))  # 儲存最佳模型權重\n",
    "                # print(f'New best model found at epoch {epoch+1} with recall: {best_recall:.4f}. Model saved.')\n",
    "                print(f'New best model found at epoch {epoch+1} with loss: {best_loss:.4f}. Model saved.')\n",
    "                print(f'Accuracy of the model on the test set: {accuracy:.2f}% / Macro F1 Score: {f1:.4f} / Macro Recall: {recall:.4f} / AUC: {auc:.4f}')\n",
    "                print(f'True Positive: {tp}({tp+fn}), False Negative: {fn}({fn+tp}), True Negative: {tn}, False Positive: {fp}')\n",
    "        #     else:\n",
    "        #         patient+=1\n",
    "        #         # print(f\"Early Stopping patient:{patient}/10\")\n",
    "        # if patient==10:\n",
    "        #     print(\"Early Stopping!!!!!!!!!!\")\n",
    "            # break\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "A ../dataset/DATA_A_FinalFinished[2024-09-27-filter-age]fixed.csv\n",
      "DATA: A | Fold CV: 1\n",
      "Epoch [1/100], Loss: 0.3677, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.4222. Model saved.\n",
      "Accuracy of the model on the test set: 0.84% / Macro F1 Score: 0.5081 / Macro Recall: 0.5210 / AUC: 0.6565\n",
      "True Positive: 407(6625), False Negative: 6218(6625), True Negative: 35333, False Positive: 699\n",
      "New best model found at epoch 3 with loss: 0.4168. Model saved.\n",
      "Accuracy of the model on the test set: 0.84% / Macro F1 Score: 0.5315 / Macro Recall: 0.5345 / AUC: 0.6756\n",
      "True Positive: 618(6625), False Negative: 6007(6625), True Negative: 35156, False Positive: 876\n",
      "Epoch [6/100], Loss: 0.2755, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.1958, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.3185, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.3928, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.2375, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.3384, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.4954, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.3373, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.3387, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.4133, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.3610, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.4651, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.2516, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.2939, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.4257, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.3869, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.3708, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.3335, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.2401, Learning Rate: 4.359998179260186e-216\n",
      "DATA: A | Fold CV: 2\n",
      "Epoch [1/100], Loss: 0.3599, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.3936. Model saved.\n",
      "Accuracy of the model on the test set: 0.84% / Macro F1 Score: 0.4773 / Macro Recall: 0.5079 / AUC: 0.7139\n",
      "True Positive: 139(6627), False Negative: 6488(6627), True Negative: 35812, False Positive: 189\n",
      "Epoch [6/100], Loss: 0.3812, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.4228, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.4183, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.2646, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.3018, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.2609, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.3014, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.2827, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.2921, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.3153, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.3738, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.2439, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.3136, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.1816, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.4042, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.3907, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.5621, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.3501, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.3755, Learning Rate: 4.359998179260186e-216\n",
      "DATA: A | Fold CV: 3\n",
      "Epoch [1/100], Loss: 0.3358, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.3999. Model saved.\n",
      "Accuracy of the model on the test set: 0.85% / Macro F1 Score: 0.5509 / Macro Recall: 0.5470 / AUC: 0.7058\n",
      "True Positive: 759(6567), False Negative: 5808(6567), True Negative: 35194, False Positive: 775\n",
      "Epoch [6/100], Loss: 0.2268, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.3575, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.3020, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.3509, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.2124, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.1534, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.2301, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.2104, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.3798, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.3389, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.2226, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.4165, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.5361, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.3806, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.5134, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.2377, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.3332, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.4611, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.2786, Learning Rate: 4.359998179260186e-216\n",
      "DATA: A | Fold CV: 4\n",
      "Epoch [1/100], Loss: 0.3681, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.4110. Model saved.\n",
      "Accuracy of the model on the test set: 0.84% / Macro F1 Score: 0.4954 / Macro Recall: 0.5151 / AUC: 0.6711\n",
      "True Positive: 284(6565), False Negative: 6281(6565), True Negative: 35496, False Positive: 471\n",
      "Epoch [6/100], Loss: 0.3432, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.5787, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.2642, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.2609, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.3413, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.4133, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.4488, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.2175, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.5263, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.2809, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.3302, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.2725, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.2078, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.3845, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.2261, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.2163, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.4110, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.3521, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.2405, Learning Rate: 4.359998179260186e-216\n",
      "DATA: A | Fold CV: 5\n",
      "Epoch [1/100], Loss: 0.3045, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.3776. Model saved.\n",
      "Accuracy of the model on the test set: 0.85% / Macro F1 Score: 0.4931 / Macro Recall: 0.5165 / AUC: 0.7541\n",
      "True Positive: 246(6657), False Negative: 6411(6657), True Negative: 35919, False Positive: 141\n",
      "Epoch [6/100], Loss: 0.3915, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.3761, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.2893, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.3003, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.2489, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.2529, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.4990, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.3147, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.2391, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.4307, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.3634, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.4363, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.2890, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.2764, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.3721, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.4077, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.2783, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.3240, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.3952, Learning Rate: 4.359998179260186e-216\n",
      "B ../dataset/DATA_B_FinalFinished[2024-09-27-filter-age]fixed.csv\n",
      "DATA: B | Fold CV: 1\n",
      "Epoch [1/100], Loss: 0.3465, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.4159. Model saved.\n",
      "Accuracy of the model on the test set: 0.84% / Macro F1 Score: 0.4790 / Macro Recall: 0.5073 / AUC: 0.6620\n",
      "True Positive: 159(6583), False Negative: 6424(6583), True Negative: 35581, False Positive: 344\n",
      "Epoch [6/100], Loss: 0.2394, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.3222, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.2678, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.3851, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.2889, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.3150, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.5026, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.4066, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.3783, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.2228, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.3483, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.1780, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.2805, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.2523, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.3621, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.3253, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.3421, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.3739, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.2803, Learning Rate: 4.359998179260186e-216\n",
      "DATA: B | Fold CV: 2\n",
      "Epoch [1/100], Loss: 0.5527, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.3948. Model saved.\n",
      "Accuracy of the model on the test set: 0.84% / Macro F1 Score: 0.4755 / Macro Recall: 0.5069 / AUC: 0.7127\n",
      "True Positive: 125(6589), False Negative: 6464(6589), True Negative: 35701, False Positive: 189\n",
      "Epoch [6/100], Loss: 0.4186, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.3169, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.2706, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.2727, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.2682, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.3640, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.2463, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.4934, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.3357, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.5145, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.3444, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.3792, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.3614, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.3738, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.3498, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.3643, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.4146, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.3513, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.4295, Learning Rate: 4.359998179260186e-216\n",
      "DATA: B | Fold CV: 3\n",
      "Epoch [1/100], Loss: 0.5784, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.4103. Model saved.\n",
      "Accuracy of the model on the test set: 0.83% / Macro F1 Score: 0.5469 / Macro Recall: 0.5432 / AUC: 0.6953\n",
      "True Positive: 819(6541), False Negative: 5722(6541), True Negative: 34440, False Positive: 1387\n",
      "Epoch [6/100], Loss: 0.5061, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.3191, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.2755, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.3175, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.2562, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.2812, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.4249, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.4133, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.2882, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.3055, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.4417, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.3142, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.3246, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.4260, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.3972, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.4329, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.4531, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.5380, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.3982, Learning Rate: 4.359998179260186e-216\n",
      "DATA: B | Fold CV: 4\n",
      "Epoch [1/100], Loss: 0.4022, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.4151. Model saved.\n",
      "Accuracy of the model on the test set: 0.84% / Macro F1 Score: 0.4743 / Macro Recall: 0.5060 / AUC: 0.6539\n",
      "True Positive: 115(6530), False Negative: 6415(6530), True Negative: 35631, False Positive: 198\n",
      "Epoch [6/100], Loss: 0.3248, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.2721, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.3337, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.5081, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.4212, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.3313, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.2977, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.1997, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.3492, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.3761, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.2122, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.3059, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.3096, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.3013, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.3294, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.2654, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.3111, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.3064, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.4082, Learning Rate: 4.359998179260186e-216\n",
      "DATA: B | Fold CV: 5\n",
      "Epoch [1/100], Loss: 0.3695, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.3777. Model saved.\n",
      "Accuracy of the model on the test set: 0.85% / Macro F1 Score: 0.5078 / Macro Recall: 0.5240 / AUC: 0.7515\n",
      "True Positive: 353(6623), False Negative: 6270(6623), True Negative: 35746, False Positive: 191\n",
      "Epoch [6/100], Loss: 0.2700, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.3098, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.4610, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.3664, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.3086, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.2752, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.3331, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.3171, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.3008, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.3116, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.3714, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.4207, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.3306, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.3423, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.2638, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.4039, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.3777, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.3204, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.3482, Learning Rate: 4.359998179260186e-216\n",
      "C ../dataset/DATA_C_FinalFinished[2024-09-27-filter-age]fixed.csv\n",
      "DATA: C | Fold CV: 1\n",
      "Epoch [1/100], Loss: 0.3188, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.4178. Model saved.\n",
      "Accuracy of the model on the test set: 0.84% / Macro F1 Score: 0.5275 / Macro Recall: 0.5316 / AUC: 0.6663\n",
      "True Positive: 470(5440), False Negative: 4970(5440), True Negative: 29736, False Positive: 707\n",
      "Epoch [6/100], Loss: 0.4304, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.3484, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.2461, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.3093, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.3442, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.2715, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.2510, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.2473, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.2589, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.2260, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.2987, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.3606, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.2767, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.2872, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.1976, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.2722, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.1779, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.3238, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.2426, Learning Rate: 4.359998179260186e-216\n",
      "DATA: C | Fold CV: 2\n",
      "Epoch [1/100], Loss: 0.2529, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.3959. Model saved.\n",
      "Accuracy of the model on the test set: 0.84% / Macro F1 Score: 0.5017 / Macro Recall: 0.5185 / AUC: 0.7209\n",
      "True Positive: 281(5372), False Negative: 5091(5372), True Negative: 28399, False Positive: 442\n",
      "Epoch [6/100], Loss: 0.4037, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.3991, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.3846, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.1529, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.1106, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.0882, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.0724, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.0622, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.4859, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 1.1501, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.2175, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.3304, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.2437, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.2351, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.6514, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.0564, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.1110, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.4542, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.0573, Learning Rate: 4.359998179260186e-216\n",
      "DATA: C | Fold CV: 3\n",
      "Epoch [1/100], Loss: 0.3664, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.4033. Model saved.\n",
      "Accuracy of the model on the test set: 0.84% / Macro F1 Score: 0.5267 / Macro Recall: 0.5315 / AUC: 0.7008\n",
      "True Positive: 443(5229), False Negative: 4786(5229), True Negative: 28439, False Positive: 634\n",
      "Epoch [6/100], Loss: 0.2342, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.2737, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.1481, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.2786, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.4590, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.2422, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.3250, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.2887, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.2431, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.3240, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.3885, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.4147, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.4020, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.1402, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.2769, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.2178, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.2938, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.2630, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.2405, Learning Rate: 4.359998179260186e-216\n",
      "DATA: C | Fold CV: 4\n",
      "Epoch [1/100], Loss: 0.5781, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.4120. Model saved.\n",
      "Accuracy of the model on the test set: 0.84% / Macro F1 Score: 0.5059 / Macro Recall: 0.5208 / AUC: 0.6812\n",
      "True Positive: 301(5299), False Negative: 4998(5299), True Negative: 28187, False Positive: 435\n",
      "Epoch [6/100], Loss: 0.4155, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.2728, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.3109, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.2225, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.2783, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.4065, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.3799, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.2070, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.2734, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.2454, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.2284, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.2914, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.4016, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.2584, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.2564, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.2646, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.3109, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.3268, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.2673, Learning Rate: 4.359998179260186e-216\n",
      "DATA: C | Fold CV: 5\n",
      "Epoch [1/100], Loss: 0.3087, Learning Rate: 0.001\n",
      "New best model found at epoch 1 with loss: 0.3742. Model saved.\n",
      "Accuracy of the model on the test set: 0.86% / Macro F1 Score: 0.5533 / Macro Recall: 0.5481 / AUC: 0.7351\n",
      "True Positive: 533(4974), False Negative: 4441(4974), True Negative: 28719, False Positive: 317\n",
      "New best model found at epoch 2 with loss: 0.3738. Model saved.\n",
      "Accuracy of the model on the test set: 0.86% / Macro F1 Score: 0.5922 / Macro Recall: 0.5741 / AUC: 0.7317\n",
      "True Positive: 852(4974), False Negative: 4122(4974), True Negative: 28367, False Positive: 669\n",
      "New best model found at epoch 3 with loss: 0.3731. Model saved.\n",
      "Accuracy of the model on the test set: 0.86% / Macro F1 Score: 0.5925 / Macro Recall: 0.5739 / AUC: 0.7335\n",
      "True Positive: 831(4974), False Negative: 4143(4974), True Negative: 28479, False Positive: 557\n",
      "Epoch [6/100], Loss: 0.2535, Learning Rate: 0.000531441\n",
      "Epoch [11/100], Loss: 0.2637, Learning Rate: 4.6383976865881075e-06\n",
      "Epoch [16/100], Loss: 0.2345, Learning Rate: 2.9063214161987073e-09\n",
      "Epoch [21/100], Loss: 0.3337, Learning Rate: 1.307320402228525e-13\n",
      "Epoch [26/100], Loss: 0.3412, Learning Rate: 4.221659203144745e-19\n",
      "Epoch [31/100], Loss: 0.3196, Learning Rate: 9.786942579887685e-26\n",
      "Epoch [36/100], Loss: 0.3674, Learning Rate: 1.628822069090375e-33\n",
      "Epoch [41/100], Loss: 0.2334, Learning Rate: 1.9460902896503433e-42\n",
      "Epoch [46/100], Loss: 0.2747, Learning Rate: 1.6692256987506204e-52\n",
      "Epoch [51/100], Loss: 0.2520, Learning Rate: 1.0278503188832632e-63\n",
      "Epoch [56/100], Loss: 0.2846, Learning Rate: 4.543676715548192e-76\n",
      "Epoch [61/100], Loss: 0.2922, Learning Rate: 1.4419417220887887e-89\n",
      "Epoch [66/100], Loss: 0.3497, Learning Rate: 3.2851161461043494e-104\n",
      "Epoch [71/100], Loss: 0.2368, Learning Rate: 5.372995604995749e-120\n",
      "Epoch [76/100], Loss: 0.1922, Learning Rate: 6.308774115858041e-137\n",
      "Epoch [81/100], Loss: 0.3162, Learning Rate: 5.3178515102204816e-155\n",
      "Epoch [86/100], Loss: 0.2111, Learning Rate: 3.218030610890831e-174\n",
      "Epoch [91/100], Loss: 0.3202, Learning Rate: 1.3979990343426084e-194\n",
      "Epoch [96/100], Loss: 0.2783, Learning Rate: 4.359998179260186e-216\n"
     ]
    }
   ],
   "source": [
    "DB_type = 'A'\n",
    "flag = ['train','val']\n",
    "\n",
    "\n",
    "Data_ = {\n",
    "    'A':'../dataset/DATA_A_FinalFinished[2024-09-27-filter-age]fixed.csv',\n",
    "    'B':'../dataset/DATA_B_FinalFinished[2024-09-27-filter-age]fixed.csv',\n",
    "    'C':'../dataset/DATA_C_FinalFinished[2024-09-27-filter-age]fixed.csv'\n",
    "    }\n",
    "\n",
    "select_cols =  ['性別', '入院方式', 'HCV','HBV','有無糖尿病','FISTULA','GRAFT','Catheter','Intact PTH','age', '體重1開始','開始血壓SBP', '開始血壓DBP',\n",
    "            '開始脈搏', '體溫', '體重實際脫水','每公斤脫水量(ml/kg)','BUN','K', 'HGB','URR%','Na', 'Ca','P',\n",
    "            '透析液 Ca','ALBUMIN','ALT (SGPT)','Alk.phosphatase','Ferritin','IRON/TIBC','MCV', 'MCHC', 'MCH','Iron','Glucose AC','RBC', 'WBC',\n",
    "            'Platelet', 'Creatinine','AST (SGOT)','TIBC','Bilirubin-T', 'Cholesterol-T', 'CRP']\n",
    "print(len(select_cols))\n",
    "# select_cols = select_cols+ ['Max Diff mbp', 'Max Diff sbp','結束脈搏','Final Judge','Raw Index','ID','洗腎紀錄時間去時分',\n",
    "#                             'fold_0','fold_1', 'fold_2', 'fold_3', 'fold_4']\n",
    "\n",
    "select_cols = select_cols+ ['Final Judge','Raw Index','ID','洗腎紀錄時間去時分',\n",
    "                            'fold_0','fold_1', 'fold_2', 'fold_3', 'fold_4']\n",
    "\n",
    "hidden_size = 128\n",
    "epoch = 100\n",
    "save_path = './mlp_ckpt' #path 1\n",
    "save_path += '/nonmark' #path 2\n",
    "\n",
    "for DB_type in ['A','B','C']:\n",
    "    print(DB_type, Data_[DB_type])\n",
    "    for fold_next in [0,1,2,3,4]:\n",
    "        if DB_type =='A':\n",
    "            cat_col_names = ['入院方式', '性別', '體溫', 'FISTULA', 'GRAFT', 'Catheter', '有無糖尿病','Intact PTH', 'HCV', 'HBV']\n",
    "        else:\n",
    "            cat_col_names = ['入院方式', '性別', 'FISTULA', 'GRAFT', 'Catheter', '有無糖尿病', 'HCV', 'HBV']\n",
    "        DATA_PROCESS = data_process()\n",
    "        train_X, train_y, cat_cols, num_cols = DATA_PROCESS.data_loader(Data_[DB_type], 'train', fold_next, select_cols ,cat_col_names)\n",
    "        val_X, val_y, _, _ = DATA_PROCESS.data_loader(Data_[DB_type], 'val', fold_next, select_cols ,cat_col_names)\n",
    "        X_train_tensor = torch.tensor(train_X.values, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(train_y.values, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(val_X.values, dtype=torch.float32)\n",
    "        y_val_tensor = torch.tensor(val_y.values, dtype=torch.float32)\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        valid_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False)\n",
    "        input_size = train_X.shape[1]\n",
    "        model = MLP(input_size, hidden_size, output_size=1)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        print(f\"DATA: {DB_type} | Fold CV: {fold_next+1}\")\n",
    "        model = trainer(model=model, save_path = os.path.join(f'{save_path}_{DB_type}'), fold_n = fold_next,\n",
    "                        TrainData=train_loader, ValidData=valid_loader, \n",
    "                        epochs=epoch, crit=criterion, opt=optimizer)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idh_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
